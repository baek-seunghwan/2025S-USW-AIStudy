# 배당사기 탐지 프로젝트 – 포트폴리오 요약

이 리포지토리는 2025 수원대 AI 스터디 대회 ML2 트랙의 배당사기 탐지 프로젝트에서 수행한 작업을 포트폴리오 용도로 정리한 것입니다. 본 문서는 한국어로 작성되었습니다.

## 프로젝트 개요

- **데이터세트**: DACON에서 제공한 자동차 보험 사기 데이터(`train.csv`, `test.csv`, `sample_submission.csv`).
- **문제**: 사기 의심 처리(fraud 발생수)를 예측하는 범주 문제로 평가 지표는 **F1 Score**입니다.
- **주요 작업**: 데이터 탐색, 전처리, 피처 엔지니어링, 여러 머신러닝/딥러닝 모델 적용 및 하이퍼파라미터 튜닝, 앙상블, 임계값 조정.

## 새로운 기술 학습 및 적용 경험

### Python 및 ML 라이브러리

Python과 `pandas`, `NumPy`를 사용하여 데이터 정제와 변형을 진행했고, `scikit‑learn`을 통해 기본 모델과 평가 지표를 테스트했습니다. `CatBoost`, `LightGBM`, `XGBoost`와 같은 최신 Gradient Boosting 프레임워크들을 학습·비교하며 모델링 능력을 키웠습니다.

### Apache Spark

피처 엔지니어링과 불균형한 데이터 분포를 효율적으로 처리하기 위해 `PySpark`를 활용했습니다. 분산 데이터프레임의 연산을 통해 대규모 데이터 처리 속도를 크게 개선했습니다.

### Apache Airflow

데이터 ingest, 피처 엔지니어링, 모델 학습, 제출 파일 생성까지의 과정을 자동화하기 위해 `Airflow`로 DAG를 구축했습니다. 스케줄러의 시간 순서 오류를 해결하여 파이프라인 안정성을 확보했습니다.

### Hadoop

과거 처리 기록과 로그를 장기적으로 저장하기 위해 `Hadoop` 분산 파일 시스템(HDFS)을 이해하고 적용했습니다.

## 역할 및 주요 성과

- **데이터 품질 개선**: 결측치 처리와 이상치 제거를 통해 데이터 분포를 정규화하고 품질을 크게 향상시켰습니다. 대표적으로 보험금 추정치(`claim_est_payout`)의 이상값을 식별해 제거함으로써 학습 안정성이 향상되었습니다.
- **피처 엔지니어링**: 월/요일을 숫자형으로 변환하고, 예상 보상금 대비 연소득 비율, 운전자 나이와 차량 나이의 차이 및 비율, 책임 비율에 보상금을 곱한 `liab_payout` 등 새로운 특징을 도출하여 모델 성능을 약 20% 개선했습니다.
- **모델 개발 및 평가**: `CatBoost`, `LightGBM`, `XGBoost` 등 다양한 모델을 개발하여 교차검증 기반으로 F1 점수를 비교했습니다. CatBoost 모델에서 하이퍼파라미터 튜닝과 임계값 조정을 통해 F1 점수를 약 0.22에서 0.36 이상으로 끌어올렸습니다.
- **대회 성적**: 최종적으로 개선된 CatBoost 모델을 이용해 데이콘 공개 리더보드에서 점수 **0.60326**을 달성하며 2등에 올랐습니다.

## 데이터 구조 및 도메인 이해

- 데이터는 100개 이상의 열로 구성되어 있으며, 차량 정보, 운전자 정보, 청구 정보 등 다양한 범주의 특성을 포함합니다. 문자형 범주는 명확하게 구분해 인코딩하고, 수치형 변수는 분포를 고려해 스케일링 또는 로그 변환을 적용했습니다.
- 보험 사기 도메인을 이해하기 위해 `liab_prct`(책임 비율), `claim_est_payout`(예상 보상금), `insurance_claim_count`(과거 청구 건수) 등 핵심 변수를 분석하고, 이들 간의 관계를 탐구해 위험도를 파악하는 특징을 설계했습니다.
- 복잡한 구조의 데이터를 시각화와 상관관계 분석을 통해 이해하고, 도메인 지식을 반영한 특징을 추가하여 모델의 일반화를 높였습니다.

## 대회 정보 및 참고

- 본 프로젝트는 데이콘(Dacon)에서 주최한 **2025 USW AI Study Competition ML2 트랙: 보험 사기 탐지** 대회에서 수행되었습니다.
- 대회 평가 지표는 **F1 Score**이며, 사기 및 정상 샘플 간 불균형 문제가 존재하여 `class_weight` 조정과 임계값 튜닝이 성과에 큰 영향을 주었습니다.